2022-08-22 19:58:18,072 INFO - Starting the scheduler
2022-08-22 19:58:18,073 INFO - Processing each file at most -1 times
2022-08-22 19:58:18,079 INFO - Launched DagFileProcessorManager with pid: 16741
2022-08-22 19:58:18,081 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:03:19,012 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:06:45,478 INFO - Exiting gracefully upon receiving signal 15
2022-08-22 20:06:46,499 INFO - Sending Signals.SIGTERM to group 16741. PIDs of all processes in the group: [16741]
2022-08-22 20:06:46,504 INFO - Sending the signal Signals.SIGTERM to group 16741
2022-08-22 20:06:48,156 INFO - Process psutil.Process(pid=16741, status='terminated', exitcode=0, started='19:58:18') (16741) terminated with exit code 0
2022-08-22 20:06:48,170 INFO - Sending Signals.SIGTERM to group 16741. PIDs of all processes in the group: []
2022-08-22 20:06:48,173 INFO - Sending the signal Signals.SIGTERM to group 16741
2022-08-22 20:06:48,177 INFO - Sending the signal Signals.SIGTERM to process 16741 as process group is missing.
2022-08-22 20:06:48,180 INFO - Exited execute loop
2022-08-22 20:35:49,020 INFO - Starting the scheduler
2022-08-22 20:35:49,021 INFO - Processing each file at most -1 times
2022-08-22 20:35:49,026 INFO - Launched DagFileProcessorManager with pid: 2908
2022-08-22 20:35:49,028 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:40:49,112 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:45:49,167 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:50:49,218 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:55:49,270 INFO - Resetting orphaned tasks for active dag runs
2022-08-22 20:58:42,021 ERROR - Exception when executing SchedulerJob._run_scheduler_loop
Traceback (most recent call last):
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag.last_parsed_time

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/jobs/scheduler_job.py", line 628, in _execute
    self._run_scheduler_loop()
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/jobs/scheduler_job.py", line 709, in _run_scheduler_loop
    num_queued_tis = self._do_scheduling(session)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/jobs/scheduler_job.py", line 782, in _do_scheduling
    self._create_dagruns_for_dags(guard, session)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/retries.py", line 76, in wrapped_function
    for attempt in run_with_db_retries(max_retries=retries, logger=logger, **retry_kwargs):
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/retries.py", line 85, in wrapped_function
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/jobs/scheduler_job.py", line 847, in _create_dagruns_for_dags
    self._create_dag_runs(query.all(), session)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3373, in all
    return list(self)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/opt/anaconda3/envs/airflow_env/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag.last_parsed_time
[SQL: SELECT dag.dag_id AS dag_dag_id, dag.root_dag_id AS dag_root_dag_id, dag.is_paused AS dag_is_paused, dag.is_subdag AS dag_is_subdag, dag.is_active AS dag_is_active, dag.last_parsed_time AS dag_last_parsed_time, dag.last_pickled AS dag_last_pickled, dag.last_expired AS dag_last_expired, dag.scheduler_lock AS dag_scheduler_lock, dag.pickle_id AS dag_pickle_id, dag.fileloc AS dag_fileloc, dag.owners AS dag_owners, dag.description AS dag_description, dag.default_view AS dag_default_view, dag.schedule_interval AS dag_schedule_interval, dag.max_active_tasks AS dag_max_active_tasks, dag.max_active_runs AS dag_max_active_runs, dag.has_task_concurrency_limits AS dag_has_task_concurrency_limits, dag.has_import_errors AS dag_has_import_errors, dag.next_dagrun AS dag_next_dagrun, dag.next_dagrun_data_interval_start AS dag_next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end AS dag_next_dagrun_data_interval_end, dag.next_dagrun_create_after AS dag_next_dagrun_create_after 
FROM dag 
WHERE dag.is_paused = 0 AND dag.is_active = 1 AND dag.has_import_errors = 0 AND dag.next_dagrun_create_after <= CURRENT_TIMESTAMP ORDER BY dag.next_dagrun_create_after
 LIMIT ? OFFSET ?]
[parameters: (10, 0)]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
2022-08-22 20:58:43,033 INFO - Sending Signals.SIGTERM to group 2908. PIDs of all processes in the group: [2908]
2022-08-22 20:58:43,033 INFO - Sending the signal Signals.SIGTERM to group 2908
2022-08-22 20:58:43,212 INFO - Process psutil.Process(pid=2908, status='terminated', exitcode=0, started='20:35:49') (2908) terminated with exit code 0
2022-08-22 20:58:43,213 INFO - Exited execute loop
