[2022-09-03 13:50:58,107] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: etl_airflow.Extraction scheduled__2022-09-03T02:00:00+00:00 [queued]>
[2022-09-03 13:50:58,111] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: etl_airflow.Extraction scheduled__2022-09-03T02:00:00+00:00 [queued]>
[2022-09-03 13:50:58,111] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-09-03 13:50:58,111] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-09-03 13:50:58,111] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-09-03 13:50:58,115] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): Extraction> on 2022-09-03 02:00:00+00:00
[2022-09-03 13:50:58,124] {standard_task_runner.py:52} INFO - Started process 40840 to run task
[2022-09-03 13:50:58,129] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'etl_airflow', 'Extraction', 'scheduled__2022-09-03T02:00:00+00:00', '--job-id', '583', '--raw', '--subdir', 'DAGS_FOLDER/etl_airflowv2.py', '--cfg-path', '/var/folders/35/pzst1sv14yld_nkt23lk_vmr0000gn/T/tmph92b3bqx', '--error-file', '/var/folders/35/pzst1sv14yld_nkt23lk_vmr0000gn/T/tmpztdm6vva']
[2022-09-03 13:50:58,130] {standard_task_runner.py:77} INFO - Job 583: Subtask Extraction
[2022-09-03 13:50:58,166] {logging_mixin.py:109} INFO - Running <TaskInstance: etl_airflow.Extraction scheduled__2022-09-03T02:00:00+00:00 [running]> on host Jonathans-MacBook-Pro.local
[2022-09-03 13:50:58,191] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=jonathan.dejesus.azor@gmail.com
AIRFLOW_CTX_DAG_OWNER=admin
AIRFLOW_CTX_DAG_ID=etl_airflow
AIRFLOW_CTX_TASK_ID=Extraction
AIRFLOW_CTX_EXECUTION_DATE=2022-09-03T02:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-03T02:00:00+00:00
[2022-09-03 13:50:59,172] {logging_mixin.py:109} INFO -      incident_report_number  ... rep_time
0               20222391738  ...     2353
1               20222391646  ...     2346
2               20222391708  ...     2340
3               20222391707  ...       27
4               20222391682  ...       37
..                      ...  ...      ...
195             20222381037  ...     1626
196             20222381066  ...     1623
197             20222381057  ...     1601
198             20222380989  ...     1559
199             20222381059  ...     1630

[200 rows x 9 columns]
[2022-09-03 13:50:59,173] {python.py:175} INFO - Done. Returned value was:      incident_report_number  ... rep_time
0               20222391738  ...     2353
1               20222391646  ...     2346
2               20222391708  ...     2340
3               20222391707  ...       27
4               20222391682  ...       37
..                      ...  ...      ...
195             20222381037  ...     1626
196             20222381066  ...     1623
197             20222381057  ...     1601
198             20222380989  ...     1559
199             20222381059  ...     1630

[200 rows x 9 columns]
[2022-09-03 13:50:59,185] {taskinstance.py:1267} INFO - Marking task as SUCCESS. dag_id=etl_airflow, task_id=Extraction, execution_date=20220903T020000, start_date=20220903T185058, end_date=20220903T185059
[2022-09-03 13:50:59,228] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-09-03 13:50:59,241] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-03 13:59:27,235] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: etl_airflow.Extraction scheduled__2022-09-03T02:00:00+00:00 [queued]>
[2022-09-03 13:59:27,240] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: etl_airflow.Extraction scheduled__2022-09-03T02:00:00+00:00 [queued]>
[2022-09-03 13:59:27,240] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-09-03 13:59:27,240] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-09-03 13:59:27,240] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-09-03 13:59:27,244] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): Extraction> on 2022-09-03 02:00:00+00:00
[2022-09-03 13:59:27,251] {standard_task_runner.py:52} INFO - Started process 41171 to run task
[2022-09-03 13:59:27,256] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'etl_airflow', 'Extraction', 'scheduled__2022-09-03T02:00:00+00:00', '--job-id', '632', '--raw', '--subdir', 'DAGS_FOLDER/etl_airflowv2.py', '--cfg-path', '/var/folders/35/pzst1sv14yld_nkt23lk_vmr0000gn/T/tmpze6481ru', '--error-file', '/var/folders/35/pzst1sv14yld_nkt23lk_vmr0000gn/T/tmp378xnoqx']
[2022-09-03 13:59:27,257] {standard_task_runner.py:77} INFO - Job 632: Subtask Extraction
[2022-09-03 13:59:27,281] {logging_mixin.py:109} INFO - Running <TaskInstance: etl_airflow.Extraction scheduled__2022-09-03T02:00:00+00:00 [running]> on host 1.0.0.127.in-addr.arpa
[2022-09-03 13:59:27,303] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=jonathan.dejesus.azor@gmail.com
AIRFLOW_CTX_DAG_OWNER=admin
AIRFLOW_CTX_DAG_ID=etl_airflow
AIRFLOW_CTX_TASK_ID=Extraction
AIRFLOW_CTX_EXECUTION_DATE=2022-09-03T02:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-03T02:00:00+00:00
[2022-09-03 13:59:28,203] {logging_mixin.py:109} INFO -      incident_report_number  ... rep_time
0               20222391738  ...     2353
1               20222391646  ...     2346
2               20222391708  ...     2340
3               20222391707  ...       27
4               20222391682  ...       37
..                      ...  ...      ...
195             20222381037  ...     1626
196             20222381066  ...     1623
197             20222381057  ...     1601
198             20222380989  ...     1559
199             20222381059  ...     1630

[200 rows x 9 columns]
[2022-09-03 13:59:28,420] {_metadata.py:99} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 64] Host is down
[2022-09-03 13:59:28,420] {_metadata.py:99} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 64] Host is down
[2022-09-03 13:59:28,421] {_metadata.py:99} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 64] Host is down
[2022-09-03 13:59:28,421] {_default.py:290} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2022-09-03 13:59:32,304] {local_task_job.py:211} WARNING - State of this instance has been externally set to None. Terminating instance.
[2022-09-03 13:59:32,309] {process_utils.py:120} INFO - Sending Signals.SIGTERM to group 41171. PIDs of all processes in the group: [41171]
[2022-09-03 13:59:32,310] {process_utils.py:75} INFO - Sending the signal Signals.SIGTERM to group 41171
[2022-09-03 13:59:32,310] {taskinstance.py:1408} ERROR - Received SIGTERM. Terminating subprocesses.
[2022-09-03 13:59:32,314] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/theonewiththelion/airflow/dags/etl_airflowv2.py", line 79, in api_extraction
    pandas_gbq.to_gbq(stg_austin_crime, table_id, project_id='crafty-shield-359406', if_exists='replace')
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/gbq.py", line 1198, in to_gbq
    connector.load_data(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/gbq.py", line 591, in load_data
    chunks = load.load_chunks(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/load.py", line 240, in load_chunks
    load_parquet(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/load.py", line 131, in load_parquet
    client.load_table_from_dataframe(
  File "/opt/anaconda3/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py", line 728, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/future/polling.py", line 132, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/future/polling.py", line 110, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/retry.py", line 283, in retry_wrapped_func
    return retry_target(
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/retry.py", line 218, in retry_target
    time.sleep(sleep)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2022-09-03 13:59:32,318] {taskinstance.py:1267} INFO - Marking task as FAILED. dag_id=etl_airflow, task_id=Extraction, execution_date=20220903T020000, start_date=20220903T185927, end_date=20220903T185932
[2022-09-03 13:59:32,325] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-09-03 13:59:32,325] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
[2022-09-03 13:59:32,326] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
[2022-09-03 13:59:32,327] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
[2022-09-03 13:59:32,327] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,328] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,328] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,329] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
[2022-09-03 13:59:32,329] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,329] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,330] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,330] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
[2022-09-03 13:59:32,337] {logging_mixin.py:109} WARNING - /opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py:102 PendingDeprecationWarning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
[2022-09-03 13:59:32,337] {configuration.py:381} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-03 13:59:32,337] {email.py:208} INFO - Email alerting: attempt 1
[2022-09-03 13:59:32,340] {configuration.py:381} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-03 13:59:32,340] {email.py:208} INFO - Email alerting: attempt 1
[2022-09-03 13:59:32,341] {taskinstance.py:1751} ERROR - Failed to send email to: jonathan.dejesus.azor@gmail.com
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/theonewiththelion/airflow/dags/etl_airflowv2.py", line 79, in api_extraction
    pandas_gbq.to_gbq(stg_austin_crime, table_id, project_id='crafty-shield-359406', if_exists='replace')
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/gbq.py", line 1198, in to_gbq
    connector.load_data(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/gbq.py", line 591, in load_data
    chunks = load.load_chunks(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/load.py", line 240, in load_chunks
    load_parquet(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/load.py", line 131, in load_parquet
    client.load_table_from_dataframe(
  File "/opt/anaconda3/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py", line 728, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/future/polling.py", line 132, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/future/polling.py", line 110, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/retry.py", line 283, in retry_wrapped_func
    return retry_target(
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/retry.py", line 218, in retry_target
    time.sleep(sleep)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2093, in email_alert
    send_email(self.task.email, subject, html_content)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 55, in send_email
    return backend(
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 102, in send_email_smtp
    send_mime_email(e_from=smtp_mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 210, in send_mime_email
    conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 244, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/opt/anaconda3/lib/python3.9/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/opt/anaconda3/lib/python3.9/smtplib.py", line 341, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/opt/anaconda3/lib/python3.9/smtplib.py", line 312, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/opt/anaconda3/lib/python3.9/socket.py", line 844, in create_connection
    raise err
  File "/opt/anaconda3/lib/python3.9/socket.py", line 832, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1749, in handle_failure
    self.email_alert(error)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2095, in email_alert
    send_email(self.task.email, subject, html_content_err)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 55, in send_email
    return backend(
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 102, in send_email_smtp
    send_mime_email(e_from=smtp_mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 210, in send_mime_email
    conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/email.py", line 244, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/opt/anaconda3/lib/python3.9/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/opt/anaconda3/lib/python3.9/smtplib.py", line 341, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/opt/anaconda3/lib/python3.9/smtplib.py", line 312, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/opt/anaconda3/lib/python3.9/socket.py", line 844, in create_connection
    raise err
  File "/opt/anaconda3/lib/python3.9/socket.py", line 832, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused
[2022-09-03 13:59:32,349] {standard_task_runner.py:89} ERROR - Failed to execute job 632 for task Extraction
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/theonewiththelion/airflow/dags/etl_airflowv2.py", line 79, in api_extraction
    pandas_gbq.to_gbq(stg_austin_crime, table_id, project_id='crafty-shield-359406', if_exists='replace')
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/gbq.py", line 1198, in to_gbq
    connector.load_data(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/gbq.py", line 591, in load_data
    chunks = load.load_chunks(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/load.py", line 240, in load_chunks
    load_parquet(
  File "/opt/anaconda3/lib/python3.9/site-packages/pandas_gbq/load.py", line 131, in load_parquet
    client.load_table_from_dataframe(
  File "/opt/anaconda3/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py", line 728, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/future/polling.py", line 132, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/future/polling.py", line 110, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/retry.py", line 283, in retry_wrapped_func
    return retry_target(
  File "/opt/anaconda3/lib/python3.9/site-packages/google/api_core/retry.py", line 218, in retry_target
    time.sleep(sleep)
  File "/opt/anaconda3/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2022-09-03 13:59:32,370] {process_utils.py:70} INFO - Process psutil.Process(pid=41171, status='terminated', exitcode=1, started='13:59:27') (41171) terminated with exit code 1
